name: Run RateMDs Full Crawler

on:
  # 允许从 GitHub 仓库的 Actions 标签页手动触发此工作流程
  workflow_dispatch:
  
  # 也可以添加定时运行 (例如每天凌晨 00:00 UTC)
  # schedule:
  #   - cron: '0 0 * * *'

jobs:
  scrape_data:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          # 使用您的脚本支持的 Python 版本
          python-version: '3.x' 

      - name: Create requirements.txt and Install Dependencies
        run: |
          echo "cloudscraper" > requirements.txt
          echo "beautifulsoup4" >> requirements.txt
          echo "requests" >> requirements.txt
          pip install -r requirements.txt

      - name: Run the full crawler script
        # 运行修改后的脚本，它将调用 main() 爬取所有页并生成 JSON 文件
        run: python ratemd_crawler.py
        
      # -------------------------------------------------------------------
      # 文件生成位置和持久化步骤
      # -------------------------------------------------------------------
      
      - name: Upload JSON as Artifact
        uses: actions/upload-artifact@v4
        with:
          # Artifact 的名称
          name: ratemds-scraped-data
          # 爬虫脚本中定义的输出文件名
          path: ratemds_facilities.json
          # 可选：设置 Artifact 的保留时间，例如 7 天
          retention-days: 7